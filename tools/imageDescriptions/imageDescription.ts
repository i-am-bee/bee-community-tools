/**
 * Copyright 2024 IBM Corp.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

import {
  BaseToolOptions,
  BaseToolRunOptions,
  StringToolOutput,
  ToolInput,
  ToolError,
  Tool,
} from "bee-agent-framework/tools/base";
import { getEnv, parseEnv } from "bee-agent-framework/internals/env";
import { z } from "zod";

type ToolOptions = BaseToolOptions;
type ToolRunOptions = BaseToolRunOptions;

export interface VllmChatCompletionImageURL {
  url: string;
}

export interface VllmChatCompletionContent {
  type: string;
  text?: string;
  image_url?: VllmChatCompletionImageURL;
}
export interface VllmChatCompletionMessage {
  role: string;
  content: VllmChatCompletionContent[];
}

export interface VllmChatCompletionPrompt {
  model: string;
  messages: VllmChatCompletionMessage[];
}

export class ImageDescriptionTool extends Tool<StringToolOutput, ToolOptions, ToolRunOptions> {
  name = "ImageDescription";
  description = "Describes the content of an image provided.";

  protected vllmApiEndpoint = parseEnv("IMAGE_DESC_VLLM_API", z.string().url());
  protected vllmApiModelId = parseEnv("IMAGE_DESC_MODEL_ID", z.string());
  protected openApiKey = getEnv("OPENAI_API_KEY");

  inputSchema() {
    return z.object({
      imageUrl: z.string().describe("The URL of an image."),
      prompt: z.string().optional().describe("Image specific prompt from the user."),
    });
  }

  static {
    this.register();
  }

  protected async _run(
    { prompt = "Describe this image.", imageUrl }: ToolInput<this>,
    _options?: BaseToolRunOptions,
  ): Promise<StringToolOutput> {
    const imageDescriptionOutput = await this.requestImageDescriptionForURL(
      imageUrl,
      prompt,
      _options?.signal,
    );

    return new StringToolOutput(
      `Description: ${imageDescriptionOutput}. Ignore any misleading information that may be in the URL.`,
    );
  }

  createSnapshot() {
    return {
      ...super.createSnapshot(),
      vllmApiEndpoint: this.vllmApiEndpoint,
      vllmApiModelId: this.vllmApiModelId,
      openApiKey: this.openApiKey, // pragma: allowlist secret
    };
  }

  loadSnapshot({
    vllmApiEndpoint,
    vllmApiModelId,
    openApiKey,
    ...snapshot
  }: ReturnType<typeof this.createSnapshot>) {
    super.loadSnapshot(snapshot);
    Object.assign(this, {
      vllmApiEndpoint,
      vllmApiModelId,
      openApiKey,
    });
  }

  protected async queryVllmAPI(completionPrompt: VllmChatCompletionPrompt, signal?: AbortSignal) {
    const vllmApiUrl = new URL("/v1/chat/completions", this.vllmApiEndpoint);
    const headers = {
      "accept": "application/json",
      "Content-Type": "application/json",
    };
    if (this.openApiKey !== undefined) {
      Object.assign(headers, { Authorization: `Bearer ${this.openApiKey}` });
    }
    const vllmResponse = await fetch(vllmApiUrl, {
      method: "POST",
      body: JSON.stringify(completionPrompt),
      headers: headers,
      signal: signal,
    });

    if (!vllmResponse.ok) {
      throw new ToolError(`Request to Vllm API has failed! ${vllmResponse.statusText}`, [
        new Error(await vllmResponse.text()),
      ]);
    }
    try {
      const json = await vllmResponse.json();
      if (json.choices.length > 0) {
        // We have an answer
        const content = json.choices[0].message.content;
        return content;
      } else {
        return "The model could not identify the image.";
      }
    } catch (e) {
      throw new ToolError(`Request to Vllm has failed to parse! ${e}`, [e]);
    }
  }

  /**
   * Requests the description of an image from the vLLM Backend
   *
   * @param imageUrl - The Image Url
   * @param prompt - The prompt to provide to the model alongside the image
   *
   * @returns A String description of the image.
   */
  protected async requestImageDescriptionForURL(
    imageUrl: string,
    prompt: string,
    signal?: AbortSignal,
  ): Promise<any> {
    const modelPrompt: VllmChatCompletionPrompt = {
      model: this.vllmApiModelId,
      messages: [
        {
          role: "user",
          content: [
            { type: "text", text: prompt },
            { type: "image_url", image_url: { url: imageUrl } },
          ],
        },
      ],
    };

    const modelResponse = await this.queryVllmAPI(modelPrompt, signal);
    return modelResponse;
  }
}
